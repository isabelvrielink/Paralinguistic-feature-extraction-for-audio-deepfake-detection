{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabelvrielink/Paralinguistic-feature-extraction-for-audio-deepfake-detection/blob/main/Coding_part_1_(testing_models_and_preprocessing_tests).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVyeFXcDjMxx",
        "outputId": "4c4d36e9-30c9-4774-996e-8ad4db5ecfbf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "Collecting kagglehub\n",
            "  Downloading kagglehub-0.2.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.2.2)\n",
            "Installing collected packages: kagglehub\n",
            "  Attempting uninstall: kagglehub\n",
            "    Found existing installation: kagglehub 0.2.4\n",
            "    Uninstalling kagglehub-0.2.4:\n",
            "      Successfully uninstalled kagglehub-0.2.4\n",
            "Successfully installed kagglehub-0.2.5\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n",
            "E: Package 'libfluidsynth1' has no installation candidate\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for libarchive\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for libarchive\n",
            "Failed to build libarchive\n",
            "\u001b[31mERROR: Could not build wheels for libarchive, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n",
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.0)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.23.0\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade kagglehub\n",
        "!pip install matplotlib-venn\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "!pip install tensorflow-hub\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "!pip install cartopy\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLVxW355XCwA"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pydot\n",
        "import cartopy\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for downloading the TRILLsson model from Kaggle"
      ],
      "metadata": {
        "id": "dnV-BPPrANIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDoJhfzIlUSN",
        "outputId": "4810ed74-561b-471c-f62e-c7be8fb1bb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/google/trillsson/tensorFlow2/1/1/download...\n",
            "100%|██████████| 19.6M/19.6M [00:02<00:00, 8.60MB/s]\n",
            "Extracting model files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to model files: /root/.cache/kagglehub/models/google/trillsson/tensorFlow2/1/1\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.model_download(\"google/trillsson/tensorFlow2/1\")\n",
        "print(\"Path to model files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for loading the TRILLsson model via TensorFlow Hub"
      ],
      "metadata": {
        "id": "KPcyQQtnAIYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvEDk41uA4m3"
      },
      "outputs": [],
      "source": [
        "model_url = 'https://tfhub.dev/google/trillsson1/1'\n",
        "model = hub.KerasLayer(model_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq4TVBcGaZId",
        "outputId": "20b29771-1401-4bce-afab-b98589023835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N7o_d_st8MKM"
      },
      "outputs": [],
      "source": [
        "# split the input audio clips into smaller clips, of 1 second\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# file path\n",
        "file_path = \"/path/to/dataset/\"\n",
        "\n",
        "# Directory to save the processed files\n",
        "output_path = \"/path/to/output/\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(file_path):\n",
        "    if filename.endswith(\".flac\"):\n",
        "        full_path = os.path.join(file_path, filename)\n",
        "        audio = AudioSegment.from_file(full_path, format=\"flac\")\n",
        "        # set it to 1 second\n",
        "        start_time = (len(audio) // 2) - 500\n",
        "        end_time = (len(audio) // 2) + 500\n",
        "        start_time = max(0, start_time)\n",
        "        end_time = min(len(audio), end_time)\n",
        "        middle_clip = audio[start_time:end_time]\n",
        "        # Save the processed clip\n",
        "        output_file = os.path.join(output_path, filename)\n",
        "        middle_clip.export(output_file, format=\"flac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTcs-OljlbUP",
        "outputId": "965a9384-6af2-448b-bb45-0c40471fedfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6uB2fpK9HdU",
        "outputId": "78a4e494-ba05-4be2-e4a1-8c8b30cc2c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all following steps are from the testround\n",
        "# The dev set of ASVspoof2019 is used here to test the paralinguistic feature extraction by TRILLsson"
      ],
      "metadata": {
        "id": "FKUwK2uxqGAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRILLsson test 3\n",
        "# save all embeddings to 1 map in format \"D\" in my directory THESIS ISABEL\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from datetime import datetime\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "# Mount Google Drive if using Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model = hub.KerasLayer('https://tfhub.dev/google/trillsson5/1')\n",
        "\n",
        "seconds = 1\n",
        "\n",
        "# To store embeddings\n",
        "embeddings_dir = '/path/to/embeddings/'\n",
        "os.makedirs(embeddings_dir, exist_ok=True)\n",
        "\n",
        "# Make sure to point to the correct files directory\n",
        "files = glob.glob('/path/to/embeddings')\n",
        "print(f\"Found {len(files)} files to process.\")\n",
        "\n",
        "for filename in files:\n",
        "  if os.path.isfile(filename):\n",
        "    head, tail = os.path.split(filename)\n",
        "    filestem = tail[:-5]\n",
        "    outfilename = f\"{embeddings_dir}/{filestem}.txt\"  # Ensure 'D' is preserved\n",
        "\n",
        "    # Check if 'D' is in the filestem to ensure it's correct\n",
        "    if 'D' not in filestem:\n",
        "      print(f\"Warning: Expected 'D' in filename but found: {filestem}\")\n",
        "\n",
        "    if not os.path.isfile(outfilename):\n",
        "      y, sr = librosa.load(filename, sr=16000)\n",
        "      segment = y[0:seconds * sr]\n",
        "      if len(segment) / sr >= 1:\n",
        "        y_mono = librosa.to_mono(segment)\n",
        "        speech = librosa.util.normalize(y_mono)\n",
        "        audio_sample = tf.convert_to_tensor(tf.reshape(speech, (1, speech.size)))\n",
        "        embedding = model(audio_sample)['embedding']\n",
        "        embedding.shape.assert_is_compatible_with([None, 1024])\n",
        "        np.savetxt(outfilename, embedding.numpy())\n",
        "\n",
        "# Check saved files in the specific directory\n",
        "saved_files = glob.glob(f\"{embeddings_dir}/*.txt\")\n",
        "print(f\"Saved {len(saved_files)} embedding files.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI3IhSCdq5Ah",
        "outputId": "97414d34-8d21-4e08-a3d8-4f1ccbe18ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 25137 files to process.\n",
            "Saved 25012 embedding files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the directory\n",
        "directory = '/path/to/embeddings/'\n",
        "\n",
        "# Get the list of all files in the directory\n",
        "files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.txt')]\n",
        "\n",
        "# Print the number of files found\n",
        "print(f\"Found {len(files)} files to process.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE7fG9usJupD",
        "outputId": "109d320a-d662-4bca-fdf7-92fb86a49484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25012 files to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the labels with the embeddings\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Path to both files\n",
        "embeddings_dir = '/path/to/embeddings'\n",
        "label_file_path = '/path/to/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
        "\n",
        "# Load labels file and put in dict\n",
        "labels_dict = {}\n",
        "with open(label_file_path, 'r') as file:\n",
        "  for line in file:\n",
        "    parts = line.strip().split()\n",
        "    file_id = parts[1] + \".txt\"\n",
        "    label = parts[-1]\n",
        "    labels_dict[file_id] = 1 if label == 'bonafide' else 0\n",
        "\n",
        "print(f\"Loaded {len(labels_dict)} labels\")\n",
        "\n",
        "# Ensure the embeddings directory exists\n",
        "if not os.path.exists(embeddings_dir):\n",
        "    print(f\"Embeddings directory {embeddings_dir} does not exist.\")\n",
        "else:\n",
        "    print(f\"Embeddings directory exists: {embeddings_dir}\")\n",
        "\n",
        "# List files in embeddings directory\n",
        "embeddings_files = os.listdir(embeddings_dir)\n",
        "print(f\"Total embeddings files: {len(embeddings_files)}\")\n",
        "\n",
        "# Sample embeddings files, to check if it works correctly\n",
        "print(\"Sample embeddings files:\", embeddings_files[:10])\n",
        "\n",
        "# Sample label identifiers, to check if it works correctly\n",
        "sample_labels = list(labels_dict.keys())[:10]\n",
        "print(\"Sample label identifiers:\", sample_labels)\n",
        "\n",
        "# Tracking pairing\n",
        "successful_loads = 0\n",
        "failed_loads = 0\n",
        "\n",
        "# Filter out duplicates and missing files\n",
        "matched_files = []\n",
        "embeddings_dict = {}\n",
        "\n",
        "for filename in embeddings_files:\n",
        "  filepath = os.path.join(embeddings_dir, filename)\n",
        "  if filename in labels_dict:\n",
        "    try:\n",
        "      embedding = np.loadtxt(filepath)\n",
        "      embeddings_dict[filename] = embedding\n",
        "      matched_files.append(filename)\n",
        "      successful_loads += 1\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to load {filename}: {e}\")\n",
        "      failed_loads += 1\n",
        "\n",
        "print(f\"Number of matched files: {len(matched_files)}\")\n",
        "print(f\"Loaded {successful_loads} embeddings\")\n",
        "print(f\"Failed to load {failed_loads} embeddings\")\n",
        "\n",
        "# Filtered out unmatched labels\n",
        "filtered_labels_dict = {k: v for k, v in labels_dict.items() if k in matched_files}\n",
        "\n",
        "print(f\"Filtered to {len(filtered_labels_dict)} matched labels\")\n",
        "\n",
        "# Create dataframe\n",
        "data = {\n",
        "    'embedding': [embeddings_dict[filename] for filename in matched_files],\n",
        "    'label': [filtered_labels_dict[filename] for filename in matched_files]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77TgMAlC8sGk",
        "outputId": "f89e3a05-252f-47fe-fca6-351aa9915b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 24844 labels\n",
            "Embeddings directory exists: /content/drive/My Drive/THESIS ISABEL/embeddings\n",
            "Total embeddings files: 25012\n",
            "Sample embeddings files: ['LA_D_3447687.txt', 'LA_D_2896345.txt', 'LA_D_7114286.txt', 'LA_D_3510615.txt', 'LA_D_4094129.txt', 'LA_D_3709416.txt', 'LA_D_9089312.txt', 'LA_D_6751883.txt', 'LA_D_2596805.txt', 'LA_D_9685224.txt']\n",
            "Sample label identifiers: ['LA_D_1047731.txt', 'LA_D_1105538.txt', 'LA_D_1125976.txt', 'LA_D_1293230.txt', 'LA_D_1340209.txt', 'LA_D_1376638.txt', 'LA_D_1377420.txt', 'LA_D_1403371.txt', 'LA_D_1590530.txt', 'LA_D_1595036.txt']\n",
            "Number of matched files: 24720\n",
            "Loaded 24720 embeddings\n",
            "Failed to load 0 embeddings\n",
            "Filtered to 24720 matched labels\n",
            "                                           embedding  label\n",
            "0  [-1.4889453649520874, -0.8926263451576233, -0....      0\n",
            "1  [-0.7889299988746643, -0.18677853047847748, -0...      1\n",
            "2  [-0.949458658695221, -0.6341816186904907, -1.1...      0\n",
            "3  [-1.273923635482788, -1.2051512002944946, -0.6...      0\n",
            "4  [-1.0891802310943604, -1.2126275300979614, -0....      0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPtMdL5hlvl2RD35dv04CXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}